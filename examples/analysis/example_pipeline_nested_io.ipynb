{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from axisfuzzy.analysis.pipeline import FuzzyPipeline\n",
    "from axisfuzzy.analysis.component.basic import (\n",
    "    ToolNormalization, ToolWeightNormalization, ToolStatistics, ToolSimpleAggregation\n",
    ")\n",
    "from axisfuzzy.analysis.build_in import ContractCrispTable, ContractWeightVector, ContractNormalizedWeights\n",
    "from example_basic_dependency_file import (ContractAccuracyVector,\n",
    "                                            ContractOrderResult,\n",
    "                                            ContractMultiMetrics,\n",
    "                                            DemoDataGenerator,\n",
    "                                            DemoScoreCalculator,\n",
    "                                            DemoMultiOutputAnalyzer,\n",
    "                                            DemoRanker,\n",
    "                                            DemoDataAggregator)\n",
    "from examples.analysis.example_components_demo import main_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac2835888bbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_preprocessing_pipeline_fixed():\n",
    "    \"\"\"\n",
    "    修正后的数据预处理子管道\n",
    "\n",
    "    重要修改：确保输出是 ContractCrispTable 而不是 ContractStatisticsDict\n",
    "\n",
    "    Pipeline: raw_data -> normalization -> normalized_data (ContractCrispTable)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FuzzyPipeline\n",
    "        A reusable data preprocessing pipeline that outputs normalized data.\n",
    "    \"\"\"\n",
    "    # Create components\n",
    "    normalizer = ToolNormalization(method='min_max', axis=0)\n",
    "\n",
    "    # Build sub-pipeline\n",
    "    preprocessing_pipeline = FuzzyPipeline(name=\"DataPreprocessing_SubPipeline\")\n",
    "\n",
    "    # Define inputs\n",
    "    raw_data = preprocessing_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # Processing steps - 注意：这里只做标准化，不计算统计量\n",
    "    # 这样输出仍然是 ContractCrispTable 类型\n",
    "    normalized_data = preprocessing_pipeline.add(normalizer.run, data=raw_data)\n",
    "\n",
    "    # 移除统计计算步骤，以保持输出为 ContractCrispTable\n",
    "    return preprocessing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da6dfe8a094a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_analysis_pipeline():\n",
    "    \"\"\"\n",
    "    创建独立的数据分析子管道（用于统计分析）\n",
    "\n",
    "    Pipeline: raw_data -> statistics -> stats_dict (ContractStatisticsDict)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FuzzyPipeline\n",
    "        A pipeline dedicated to statistical analysis.\n",
    "    \"\"\"\n",
    "    # Create components\n",
    "    stats_calculator = ToolStatistics(axis=1)\n",
    "\n",
    "    # Build sub-pipeline\n",
    "    analysis_pipeline = FuzzyPipeline(name=\"DataAnalysis_SubPipeline\")\n",
    "\n",
    "    # Define inputs\n",
    "    input_data = analysis_pipeline.input(\"input_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # Processing steps\n",
    "    data_stats = analysis_pipeline.add(stats_calculator.run, data=input_data)\n",
    "\n",
    "    return analysis_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca07a1cb9269877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scoring_pipeline_fixed():\n",
    "    \"\"\"\n",
    "    修正后的评分子管道（保持不变，因为合约已经正确）\n",
    "\n",
    "    Pipeline: {processed_data, weights} -> score_calculation -> ranking -> {scores, rankings}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    FuzzyPipeline\n",
    "        A reusable scoring and ranking pipeline.\n",
    "    \"\"\"\n",
    "    # Create components\n",
    "    score_calculator = DemoScoreCalculator(score_method='weighted_sum')\n",
    "    ranker = DemoRanker(ascending=False)\n",
    "\n",
    "    # Build sub-pipeline\n",
    "    scoring_pipeline = FuzzyPipeline(name=\"Scoring_SubPipeline\")\n",
    "\n",
    "    # Define inputs\n",
    "    processed_data = scoring_pipeline.input(\"processed_data\", contract=ContractCrispTable)\n",
    "    weights = scoring_pipeline.input(\"weights\", contract=ContractNormalizedWeights)\n",
    "\n",
    "    # Processing steps\n",
    "    scores = scoring_pipeline.add(score_calculator.run, data=processed_data, weights=weights)\n",
    "    rankings = scoring_pipeline.add(ranker.run, scores=scores)\n",
    "\n",
    "    return scoring_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18edfba60e8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_simple_nested_pipeline_fixed():\n",
    "    \"\"\"\n",
    "    修正后的简单嵌套管道演示\n",
    "\n",
    "    Main Pipeline: raw_data -> [DataPreprocessing SubPipeline] -> [Scoring SubPipeline] -> final_results\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Demo: Fixed Simple Nested Pipeline (2-level nesting)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create sub-pipelines - 使用修正后的版本\n",
    "    preprocessing_sub = create_data_preprocessing_pipeline_fixed()\n",
    "    scoring_sub = create_scoring_pipeline_fixed()\n",
    "\n",
    "    # Create main pipeline\n",
    "    main_pipeline = FuzzyPipeline(name=\"Main_NestedPipeline_Fixed\")\n",
    "\n",
    "    # Define main inputs\n",
    "    raw_data = main_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "    raw_weights = main_pipeline.input(\"raw_weights\", contract=ContractWeightVector)\n",
    "\n",
    "    # Add weight normalization\n",
    "    weight_normalizer = ToolWeightNormalization()\n",
    "    normalized_weights = main_pipeline.add(weight_normalizer.run, weights=raw_weights)\n",
    "\n",
    "    # Add nested preprocessing pipeline\n",
    "    # 现在 preprocessing_result 是 ContractCrispTable 类型\n",
    "    preprocessing_result = main_pipeline.add(\n",
    "        preprocessing_sub,\n",
    "        raw_data=raw_data\n",
    "    )\n",
    "\n",
    "    # Add nested scoring pipeline\n",
    "    # 合约匹配：ContractCrispTable -> ContractCrispTable ✓\n",
    "    final_result = main_pipeline.add(\n",
    "        scoring_sub,\n",
    "        processed_data=preprocessing_result,\n",
    "        weights=normalized_weights\n",
    "    )\n",
    "\n",
    "    # Test data\n",
    "    test_data = pd.DataFrame({\n",
    "        'Criterion1': [0.8, 0.6, 0.9, 0.7, 0.85],\n",
    "        'Criterion2': [0.7, 0.8, 0.6, 0.9, 0.75],\n",
    "        'Criterion3': [0.9, 0.7, 0.8, 0.6, 0.80]\n",
    "    }, index=['Alt1', 'Alt2', 'Alt3', 'Alt4', 'Alt5'])\n",
    "\n",
    "    test_weights = np.array([0.4, 0.35, 0.25])\n",
    "\n",
    "    # Run nested pipeline\n",
    "    result = main_pipeline.run({\n",
    "        \"raw_data\": test_data,\n",
    "        \"raw_weights\": test_weights\n",
    "    })\n",
    "\n",
    "    print(f\"Input data shape: {test_data.shape}\")\n",
    "    print(f\"Input weights: {test_weights}\")\n",
    "    print(f\"Final result type: {type(result)}\")\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(result)\n",
    "\n",
    "    return main_pipeline, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1285098a0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_comprehensive_nested_pipeline():\n",
    "    \"\"\"\n",
    "    展示如何同时使用预处理和分析管道的完整演示\n",
    "\n",
    "    Main Pipeline:\n",
    "    - Branch 1: raw_data -> preprocessing -> scoring\n",
    "    - Branch 2: raw_data -> analysis -> statistics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Demo: Comprehensive Nested Pipeline with Analysis Branch\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create all sub-pipelines\n",
    "    preprocessing_sub = create_data_preprocessing_pipeline_fixed()\n",
    "    scoring_sub = create_scoring_pipeline_fixed()\n",
    "    analysis_sub = create_data_analysis_pipeline()\n",
    "\n",
    "    # Create main pipeline\n",
    "    main_pipeline = FuzzyPipeline(name=\"Comprehensive_NestedPipeline\")\n",
    "\n",
    "    # Define main inputs\n",
    "    raw_data = main_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "    raw_weights = main_pipeline.input(\"raw_weights\", contract=ContractWeightVector)\n",
    "\n",
    "    # Weight normalization\n",
    "    weight_normalizer = ToolWeightNormalization()\n",
    "    normalized_weights = main_pipeline.add(weight_normalizer.run, weights=raw_weights)\n",
    "\n",
    "    # Branch 1: Preprocessing + Scoring\n",
    "    preprocessed_data = main_pipeline.add(\n",
    "        preprocessing_sub,\n",
    "        raw_data=raw_data\n",
    "    )\n",
    "\n",
    "    scoring_results = main_pipeline.add(\n",
    "        scoring_sub,\n",
    "        processed_data=preprocessed_data,\n",
    "        weights=normalized_weights\n",
    "    )\n",
    "\n",
    "    # Branch 2: Statistical Analysis (独立分支)\n",
    "    statistical_results = main_pipeline.add(\n",
    "        analysis_sub,\n",
    "        input_data=raw_data  # 直接使用原始数据进行统计分析\n",
    "    )\n",
    "\n",
    "    # Test data\n",
    "    test_data = pd.DataFrame({\n",
    "        'Performance': [85, 78, 92, 88, 75],\n",
    "        'Quality': [90, 85, 88, 92, 80],\n",
    "        'Cost': [70, 95, 85, 75, 90]\n",
    "    }, index=['Product_A', 'Product_B', 'Product_C', 'Product_D', 'Product_E'])\n",
    "\n",
    "    test_weights = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "    # Run comprehensive nested pipeline\n",
    "    result = main_pipeline.run({\n",
    "        \"raw_data\": test_data,\n",
    "        \"raw_weights\": test_weights\n",
    "    })\n",
    "\n",
    "    print(f\"Input data shape: {test_data.shape}\")\n",
    "    print(f\"Input weights: {test_weights}\")\n",
    "    print(f\"Final result type: {type(result)}\")\n",
    "    print(\"\\nComprehensive Results:\")\n",
    "    if isinstance(result, dict):\n",
    "        for key, value in result.items():\n",
    "            print(f\"\\n{key}:\")\n",
    "            print(f\"  Type: {type(value)}\")\n",
    "            print(f\"  Value: {value}\")\n",
    "    else:\n",
    "        print(result)\n",
    "\n",
    "    return main_pipeline, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94435b04d94b3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipeline1, result1 = demo_simple_nested_pipeline_fixed()\n",
    "main_pipeline2, result2 = demo_comprehensive_nested_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d68dc602f3b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipeline1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bb72f7cc8e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipeline2.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd87e4daad0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a87106c3667ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f96447092c898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acb43a3316c86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb044ba93bef687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaa9e962dad800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_level3_data_cleaning_pipeline():\n",
    "    \"\"\"\n",
    "    Level 3: 基础数据清洗管道\n",
    "\n",
    "    Pipeline: raw_data -> outlier_removal -> cleaned_data\n",
    "    \"\"\"\n",
    "    cleaning_pipeline = FuzzyPipeline(name=\"Level3_DataCleaning\")\n",
    "\n",
    "    # 输入\n",
    "    raw_data = cleaning_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # 简单的数据清洗（使用标准化作为清洗步骤的示例）\n",
    "    normalizer = ToolNormalization(method='z_score', axis=0)\n",
    "    cleaned_data = cleaning_pipeline.add(normalizer.run, data=raw_data)\n",
    "\n",
    "    return cleaning_pipeline\n",
    "\n",
    "\n",
    "def create_level3_feature_engineering_pipeline():\n",
    "    \"\"\"\n",
    "    Level 3: 特征工程管道\n",
    "\n",
    "    Pipeline: cleaned_data -> feature_transformation -> engineered_features\n",
    "    \"\"\"\n",
    "    feature_pipeline = FuzzyPipeline(name=\"Level3_FeatureEngineering\")\n",
    "\n",
    "    # 输入\n",
    "    cleaned_data = feature_pipeline.input(\"cleaned_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # 特征工程（使用聚合作为特征工程的示例）\n",
    "    aggregator = ToolSimpleAggregation(operation='mean', axis=1)\n",
    "    feature_scores = feature_pipeline.add(aggregator.run, data=cleaned_data)\n",
    "\n",
    "    # 将聚合结果转换回DataFrame格式以保持合约兼容性\n",
    "    def convert_to_dataframe(scores):\n",
    "        \"\"\"将Series转换为单列DataFrame\"\"\"\n",
    "        if isinstance(scores, pd.Series):\n",
    "            return pd.DataFrame({'aggregated_feature': scores})\n",
    "        return scores\n",
    "\n",
    "    # 标记为合约方法\n",
    "    convert_to_dataframe._is_contract_method = True\n",
    "    convert_to_dataframe._contract_inputs = {'scores': 'ContractWeightVector'}\n",
    "    convert_to_dataframe._contract_outputs = {'output': 'ContractCrispTable'}\n",
    "\n",
    "    engineered_features = feature_pipeline.add(convert_to_dataframe, scores=feature_scores)\n",
    "\n",
    "    return feature_pipeline\n",
    "\n",
    "\n",
    "def create_level2_preprocessing_pipeline():\n",
    "    \"\"\"\n",
    "    Level 2: 综合预处理管道（嵌套Level 3管道）\n",
    "\n",
    "    Pipeline: raw_data -> [Level3_DataCleaning] -> [Level3_FeatureEngineering] -> processed_data\n",
    "    \"\"\"\n",
    "    preprocessing_pipeline = FuzzyPipeline(name=\"Level2_Preprocessing\")\n",
    "\n",
    "    # 输入\n",
    "    raw_data = preprocessing_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # 嵌套Level 3管道\n",
    "    cleaning_sub = create_level3_data_cleaning_pipeline()\n",
    "    feature_sub = create_level3_feature_engineering_pipeline()\n",
    "\n",
    "    # 数据清洗\n",
    "    cleaned_data = preprocessing_pipeline.add(\n",
    "        cleaning_sub,\n",
    "        raw_data=raw_data\n",
    "    )\n",
    "\n",
    "    # 特征工程\n",
    "    processed_data = preprocessing_pipeline.add(\n",
    "        feature_sub,\n",
    "        cleaned_data=cleaned_data\n",
    "    )\n",
    "\n",
    "    return preprocessing_pipeline\n",
    "\n",
    "\n",
    "def create_level2_analysis_pipeline():\n",
    "    \"\"\"\n",
    "    Level 2: 综合分析管道\n",
    "\n",
    "    Pipeline: processed_data -> multi_analysis -> analysis_results\n",
    "    \"\"\"\n",
    "    analysis_pipeline = FuzzyPipeline(name=\"Level2_Analysis\")\n",
    "\n",
    "    # 输入\n",
    "    processed_data = analysis_pipeline.input(\"processed_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # 多维度分析\n",
    "    multi_analyzer = DemoMultiOutputAnalyzer()\n",
    "    analysis_results = analysis_pipeline.add(multi_analyzer.run, data=processed_data)\n",
    "\n",
    "    return analysis_pipeline\n",
    "\n",
    "\n",
    "def create_level1_master_pipeline():\n",
    "    \"\"\"\n",
    "    Level 1: 主控管道（嵌套Level 2管道）\n",
    "\n",
    "    Complex 3-Level Nested Pipeline:\n",
    "    raw_data -> [Level2_Preprocessing] -> [Level2_Analysis] -> final_results\n",
    "    \"\"\"\n",
    "    master_pipeline = FuzzyPipeline(name=\"Level1_Master_ComplexNested\")\n",
    "\n",
    "    # 输入\n",
    "    raw_data = master_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "\n",
    "    # 嵌套Level 2管道\n",
    "    preprocessing_sub = create_level2_preprocessing_pipeline()\n",
    "    analysis_sub = create_level2_analysis_pipeline()\n",
    "\n",
    "    # 预处理阶段\n",
    "    processed_data = master_pipeline.add(\n",
    "        preprocessing_sub,\n",
    "        raw_data=raw_data\n",
    "    )\n",
    "\n",
    "    # 分析阶段\n",
    "    final_results = master_pipeline.add(\n",
    "        analysis_sub,\n",
    "        processed_data=processed_data\n",
    "    )\n",
    "\n",
    "    return master_pipeline\n",
    "\n",
    "\n",
    "def demo_complex_nested_pipeline():\n",
    "    \"\"\"\n",
    "    演示复杂的3层嵌套管道\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Demo: Complex 3-Level Nested Pipeline\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 创建复杂嵌套管道\n",
    "    master_pipeline = create_level1_master_pipeline()\n",
    "\n",
    "    # 测试数据\n",
    "    test_data = pd.DataFrame({\n",
    "        'Metric_A': [85.2, 78.1, 92.5, 88.7, 75.3, 91.2, 83.8],\n",
    "        'Metric_B': [90.1, 85.5, 88.9, 92.3, 80.7, 87.6, 89.4],\n",
    "        'Metric_C': [70.5, 95.2, 85.1, 75.8, 90.3, 82.7, 88.1],\n",
    "        'Metric_D': [88.3, 76.9, 91.7, 85.4, 87.8, 79.5, 92.0]\n",
    "    }, index=['Entity_1', 'Entity_2', 'Entity_3', 'Entity_4', 'Entity_5', 'Entity_6', 'Entity_7'])\n",
    "\n",
    "    print(f\"Input Data Shape: {test_data.shape}\")\n",
    "    print(\"Input Data Preview:\")\n",
    "    print(test_data.head(3))\n",
    "\n",
    "    # 执行复杂嵌套管道\n",
    "    try:\n",
    "        result = master_pipeline.run({\"raw_data\": test_data})\n",
    "\n",
    "        print(f\"\\nComplex Nested Pipeline Result Type: {type(result)}\")\n",
    "        print(\"Final Results:\")\n",
    "        if isinstance(result, dict):\n",
    "            for key, value in result.items():\n",
    "                print(f\"\\n{key}:\")\n",
    "                print(f\"  Type: {type(value)}\")\n",
    "                if hasattr(value, 'shape'):\n",
    "                    print(f\"  Shape: {value.shape}\")\n",
    "                print(f\"  Content: {value}\")\n",
    "        else:\n",
    "            print(result)\n",
    "\n",
    "        # 展示管道结构\n",
    "        print(f\"\\nPipeline Structure:\")\n",
    "        print(f\"Total Steps: {len(master_pipeline.steps)}\")\n",
    "        print(f\"Input Nodes: {list(master_pipeline.input_nodes.keys())}\")\n",
    "\n",
    "        return master_pipeline, result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing complex nested pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def demo_deeply_nested_pipeline():\n",
    "    \"\"\"\n",
    "    演示极深层嵌套管道（4层嵌套）\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Demo: Deeply Nested Pipeline (4-Level)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Level 4: 原子操作管道\n",
    "    def create_level4_atomic_operations():\n",
    "        atomic_pipeline = FuzzyPipeline(name=\"Level4_AtomicOps\")\n",
    "\n",
    "        input_data = atomic_pipeline.input(\"input_data\", contract=ContractCrispTable)\n",
    "\n",
    "        # 最基础的操作\n",
    "        normalizer = ToolNormalization(method='min_max', axis=1)\n",
    "        normalized = atomic_pipeline.add(normalizer.run, data=input_data)\n",
    "\n",
    "        return atomic_pipeline\n",
    "\n",
    "    # Level 3: 组合Level 4操作\n",
    "    def create_level3_composite():\n",
    "        composite_pipeline = FuzzyPipeline(name=\"Level3_Composite\")\n",
    "\n",
    "        input_data = composite_pipeline.input(\"input_data\", contract=ContractCrispTable)\n",
    "\n",
    "        atomic_sub = create_level4_atomic_operations()\n",
    "        processed = composite_pipeline.add(atomic_sub, input_data=input_data)\n",
    "\n",
    "        return composite_pipeline\n",
    "\n",
    "    # Level 2: 组合Level 3操作\n",
    "    def create_level2_integrated():\n",
    "        integrated_pipeline = FuzzyPipeline(name=\"Level2_Integrated\")\n",
    "\n",
    "        input_data = integrated_pipeline.input(\"input_data\", contract=ContractCrispTable)\n",
    "\n",
    "        composite_sub = create_level3_composite()\n",
    "        result = integrated_pipeline.add(composite_sub, input_data=input_data)\n",
    "\n",
    "        return integrated_pipeline\n",
    "\n",
    "    # Level 1: 主控管道\n",
    "    deeply_nested_pipeline = FuzzyPipeline(name=\"Level1_DeeplyNested\")\n",
    "\n",
    "    raw_data = deeply_nested_pipeline.input(\"raw_data\", contract=ContractCrispTable)\n",
    "\n",
    "    integrated_sub = create_level2_integrated()\n",
    "    final_result = deeply_nested_pipeline.add(integrated_sub, input_data=raw_data)\n",
    "\n",
    "    # 测试数据\n",
    "    test_data = pd.DataFrame(np.random.rand(4, 3) * 100,\n",
    "                           columns=['Dim1', 'Dim2', 'Dim3'],\n",
    "                           index=['Sample1', 'Sample2', 'Sample3', 'Sample4'])\n",
    "\n",
    "    print(f\"Input Data for 4-Level Nesting:\")\n",
    "    print(test_data)\n",
    "\n",
    "    # 执行4层嵌套管道\n",
    "    result = deeply_nested_pipeline.run({\"raw_data\": test_data})\n",
    "\n",
    "    print(f\"\\nDeeply Nested Pipeline Result:\")\n",
    "    print(f\"Type: {type(result)}\")\n",
    "    print(f\"Shape: {result.shape if hasattr(result, 'shape') else 'N/A'}\")\n",
    "    print(result)\n",
    "\n",
    "    return deeply_nested_pipeline, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f53e9a67664a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_pipeline = create_level3_data_cleaning_pipeline()\n",
    "feature_pipeline = create_level3_feature_engineering_pipeline()\n",
    "preprocessing_pipeline = create_level2_preprocessing_pipeline()\n",
    "analysis_pipeline = create_level2_analysis_pipeline()\n",
    "master_pipeline = create_level1_master_pipeline()\n",
    "complex_pipeline, result_master = demo_complex_nested_pipeline()\n",
    "deeply_nested_pipeline, result_nested = demo_deeply_nested_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f56772d5a5dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning_pipeline.visualize()\n",
    "# feature_pipeline.visualize()\n",
    "# preprocessing_pipeline.visualize()\n",
    "# analysis_pipeline.visualize()\n",
    "# master_pipeline.visualize()\n",
    "# complex_pipeline.visualize()\n",
    "# deeply_nested_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217c35b85002f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc65f0a97e754bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9513c42570a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AxisFuzzy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
