{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Demonstration of FuzzyPipeline's support for various I/O scenarios.\n",
    "This script showcases:\n",
    "1. Single Input -> Single Output\n",
    "2. Single Input -> Multiple Outputs\n",
    "3. Multiple Inputs -> Single Output\n",
    "4. Multiple Inputs -> Multiple Outputs\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "# Assuming the provided library structure\n",
    "from axisfuzzy.analysis.pipeline import FuzzyPipeline\n",
    "from axisfuzzy.analysis.component.base import AnalysisComponent\n",
    "from axisfuzzy.analysis.component.basic import ToolNormalization\n",
    "from axisfuzzy.analysis.contracts import contract\n",
    "from axisfuzzy.analysis.build_in import (\n",
    "    ContractCrispTable,\n",
    "    ContractWeightVector,\n",
    "    ContractScoreVector\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f97d308",
   "metadata": {},
   "source": [
    "# Complete pipeline construction example\n",
    "pipeline = FuzzyPipeline(name=\"Comprehensive Analysis\")\n",
    "\n",
    "# Define multiple inputs with contracts\n",
    "raw_data = pipeline.input(\"data\", contract=CrispTable)\n",
    "weights = pipeline.input(\"weights\", contract=WeightVector)\n",
    "\n",
    "# Build processing chain\n",
    "normalized_data = pipeline.add(normalizer.run, data=raw_data)\n",
    "normalized_weights = pipeline.add(weight_norm.run, weights=weights)\n",
    "statistics = pipeline.add(stats_calc.run, data=normalized_data)\n",
    "\n",
    "# Execute with input data\n",
    "results = pipeline.run(initial_data={\n",
    "    \"data\": dataframe,\n",
    "    \"weights\": weight_vector\n",
    "})\n",
    "\n",
    "# Alternative: step-by-step execution for debugging\n",
    "for step_info in pipeline.iter_run(initial_data):\n",
    "    print(f\"Completed: {step_info['step_name']}\")\n",
    "    print(f\"Result: {step_info['result']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0b5d1ec",
   "metadata": {},
   "source": [
    "# Complete pipeline construction example\n",
    "pipeline = FuzzyPipeline(name=\"Comprehensive Analysis\")\n",
    "\n",
    "# Define multiple inputs with contracts\n",
    "raw_data = pipeline.input(\"data\", contract=CrispTable)\n",
    "weights = pipeline.input(\"weights\", contract=WeightVector)\n",
    "\n",
    "# Build processing chain\n",
    "normalized_data = pipeline.add(normalizer.run, data=raw_data)\n",
    "normalized_weights = pipeline.add(weight_norm.run, weights=weights)\n",
    "statistics = pipeline.add(stats_calc.run, data=normalized_data)\n",
    "\n",
    "# Execute with input data\n",
    "results = pipeline.run(initial_data={\n",
    "    \"data\": dataframe,\n",
    "    \"weights\": weight_vector\n",
    "})\n",
    "\n",
    "# Alternative: step-by-step execution for debugging\n",
    "for step_info in pipeline.iter_run(initial_data):\n",
    "    print(f\"Completed: {step_info['step_name']}\")\n",
    "    print(f\"Result: {step_info['result']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9ab3e00f23dc194",
   "metadata": {},
   "source": [
    "class ToolSplitter(AnalysisComponent):\n",
    "    \"\"\"\n",
    "    A test component that takes one table and splits it into two vectors.\n",
    "    Demonstrates: Single Input -> Multiple Outputs.\n",
    "    \"\"\"\n",
    "    def get_config(self) -> dict:\n",
    "        return {}\n",
    "\n",
    "    @contract\n",
    "    def run(self, data: ContractCrispTable) -> Dict[str, ContractWeightVector]:\n",
    "        \"\"\"\n",
    "        Splits a DataFrame into the first row and the first column.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ContractCrispTable\n",
    "            Input DataFrame.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, ContractWeightVector]\n",
    "            A dictionary containing two outputs: 'first_row' and 'first_col'.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'first_row': data.iloc[0, :],\n",
    "            'first_col': data.iloc[:, 0]\n",
    "        }\n",
    "\n",
    "\n",
    "class ToolCombiner(AnalysisComponent):\n",
    "    \"\"\"\n",
    "    A test component that combines two vectors into a single score vector.\n",
    "    Demonstrates: Multiple Inputs -> Single Output.\n",
    "    \"\"\"\n",
    "    def get_config(self) -> dict:\n",
    "        return {}\n",
    "\n",
    "    @contract\n",
    "    def run(self, vector_a: ContractWeightVector, vector_b: ContractWeightVector) -> ContractScoreVector:\n",
    "        \"\"\"\n",
    "        Combines two vectors by element-wise addition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vector_a : ContractWeightVector\n",
    "            The first input vector.\n",
    "        vector_b : ContractWeightVector\n",
    "            The second input vector.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ContractScoreVector\n",
    "            The resulting combined vector.\n",
    "        \"\"\"\n",
    "        # Ensure they are numpy arrays for robust addition\n",
    "        vec_a = pd.Series(vector_a).values\n",
    "        vec_b = pd.Series(vector_b).values\n",
    "        return vec_a + vec_b"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63d3d2401e7be73f",
   "metadata": {},
   "source": [
    "# --- Test Data ---\n",
    "sample_df1 = pd.DataFrame(\n",
    "    np.arange(9).reshape(3, 3),\n",
    "    columns=['A', 'B', 'C'],\n",
    "    index=['X', 'Y', 'Z']\n",
    ")\n",
    "sample_df2 = pd.DataFrame(\n",
    "    np.random.rand(3, 3) * 10,\n",
    "    columns=['A', 'B', 'C'],\n",
    "    index=['X', 'Y', 'Z']\n",
    ")\n",
    "sample_weights = pd.Series([0.1, 0.5, 0.4], index=['A', 'B', 'C'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce5720bf2739d947",
   "metadata": {},
   "source": [
    "sample_df1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "766d261e85e5f26e",
   "metadata": {},
   "source": [
    "sample_df2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a70806078795c22",
   "metadata": {},
   "source": [
    "sample_weights"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94d286fcd4a33b41",
   "metadata": {},
   "source": [
    "# --- 1. Scenario A: Single Input -> Single Output ---\n",
    "print(\"\\n--- Scenario A: Single Input -> Single Output ---\")\n",
    "p_a = FuzzyPipeline(name=\"SingleIn_SingleOut\")\n",
    "norm_tool = ToolNormalization(method='sum', axis=1)\n",
    "\n",
    "input_a = p_a.input(name=\"data_in\", contract=ContractCrispTable)\n",
    "output_a = p_a.add(norm_tool.run, data=input_a)\n",
    "\n",
    "result_a = p_a.run(initial_data=sample_df1)\n",
    "print(\"Input DataFrame:\\n\", sample_df1)\n",
    "print(\"\\nOutput (Normalized DataFrame):\\n\", result_a)\n",
    "p_a.visualize()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "157fec02c3d23ded",
   "metadata": {},
   "source": [
    "# --- 2. Scenario B: Single Input -> Multiple Outputs ---\n",
    "print(\"\\n--- Scenario B: Single Input -> Multiple Outputs ---\")\n",
    "p_b = FuzzyPipeline(name=\"SingleIn_MultiOut\")\n",
    "splitter_tool = ToolSplitter()\n",
    "\n",
    "input_b = p_b.input(name=\"data_in\", contract=ContractCrispTable)\n",
    "# The `add` method returns a dictionary of StepOutput objects\n",
    "outputs_b = p_b.add(splitter_tool.run, data=input_b)\n",
    "\n",
    "result_b = p_b.run(initial_data=sample_df1)\n",
    "print(\"Input DataFrame:\\n\", sample_df1)\n",
    "print(\"\\nOutput (Dictionary of results):\\n\", result_b)\n",
    "# Note: The pipeline automatically handles multiple terminal nodes.\n",
    "# The result is a dictionary mapping step display names to their outputs.\n",
    "p_b.visualize()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c0785e54205831c",
   "metadata": {},
   "source": [
    "# --- 3. Scenario C: Multiple Inputs -> Single Output ---\n",
    "print(\"\\n--- Scenario C: Multiple Inputs -> Single Output ---\")\n",
    "p_c = FuzzyPipeline(name=\"MultiIn_SingleOut\")\n",
    "combiner_tool = ToolCombiner()\n",
    "\n",
    "input_c1 = p_c.input(name=\"vec1\", contract=ContractWeightVector)\n",
    "input_c2 = p_c.input(name=\"vec2\", contract=ContractWeightVector)\n",
    "output_c = p_c.add(combiner_tool.run, vector_a=input_c1, vector_b=input_c2)\n",
    "\n",
    "result_c = p_c.run(initial_data={\n",
    "    \"vec1\": sample_df1.iloc[0, :],\n",
    "    \"vec2\": sample_weights\n",
    "})\n",
    "print(\"Input Vector 1:\\n\", sample_df1.iloc[0, :])\n",
    "print(\"\\nInput Vector 2:\\n\", sample_weights)\n",
    "print(\"\\nOutput (Combined Vector):\\n\", result_c)\n",
    "p_c.visualize()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "716514bc29d14b9e",
   "metadata": {},
   "source": [
    "# --- 4. Scenario D: Multiple Inputs -> Multiple Outputs ---\n",
    "print(\"\\n--- Scenario D: Multiple Inputs -> Multiple Outputs ---\")\n",
    "p_d = FuzzyPipeline(name=\"MultiIn_MultiOut\")\n",
    "# Reusing tools from previous scenarios\n",
    "norm_tool_d = ToolNormalization(method='max', axis=0)\n",
    "splitter_tool_d = ToolSplitter()\n",
    "\n",
    "# Define two inputs\n",
    "input_d1 = p_d.input(name=\"main_data\", contract=ContractCrispTable)\n",
    "input_d2 = p_d.input(name=\"secondary_data\", contract=ContractCrispTable)\n",
    "\n",
    "# Create two separate, parallel branches from the inputs\n",
    "# Branch 1: Normalize the main data\n",
    "norm_output = p_d.add(norm_tool_d.run, data=input_d1)\n",
    "# Branch 2: Split the secondary data\n",
    "split_outputs = p_d.add(splitter_tool_d.run, data=input_d2)\n",
    "\n",
    "# The pipeline has two terminal nodes: norm_output and the splitter step.\n",
    "# The run method will collect results from both.\n",
    "result_d = p_d.run(initial_data={\n",
    "    \"main_data\": sample_df1,\n",
    "    \"secondary_data\": sample_df2\n",
    "})\n",
    "print(\"Input 'main_data':\\n\", sample_df1)\n",
    "print(\"\\nInput 'secondary_data':\\n\", sample_df2)\n",
    "print(\"\\nOutput (Dictionary from multiple terminal nodes):\\n\", result_d)\n",
    "p_d.visualize()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8404ce854dbc0d46",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76d6065062bb5b47",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e036ea9f11288b2d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b27fb77402bdfb33",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d07e6aba799a891",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b4fd25ee26f05ed",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f6983e9ccacd59c",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7524f129082bab07",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eca5ef24eee9972b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c7684691723a015",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
